{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import ast\n",
    "import copy\n",
    "import functools\n",
    "import gc\n",
    "import itertools\n",
    "import logging\n",
    "import operator\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import socket\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from enum import Enum\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import PrettyPrinter, pprint\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import humanize\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from matplotlib import cm, patches, pyplot as plt\n",
    "from numpy import ndarray\n",
    "from numpy.random import RandomState\n",
    "from progressbar import progressbar as pbar\n",
    "from pymicro.file import file_utils\n",
    "from sklearn import metrics, metrics as met, model_selection, preprocessing\n",
    "from skimage import measure as skimage_measure\n",
    "import tabulate\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import (\n",
    "    callbacks as keras_callbacks,\n",
    "    layers,\n",
    "    losses,\n",
    "    metrics as keras_metrics,\n",
    "    optimizers,\n",
    "    utils,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from yaml import YAMLObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from tomo2seg import (\n",
    "    analyse as tomo2seg_analyse,\n",
    "    callbacks as tomo2seg_callbacks,\n",
    "    data as tomo2seg_data,\n",
    "    datasets as tomo2seg_datasets,\n",
    "    hosts,\n",
    "    losses as tomo2seg_losses,\n",
    "    schedule as tomo2seg_schedule,\n",
    "    slack,\n",
    "    slackme,\n",
    "    utils as tomo2seg_utils,\n",
    "    viz as tomo2seg_viz,\n",
    "    volume_sequence,\n",
    ")\n",
    "from tomo2seg.data import EstimationVolume, Volume\n",
    "from tomo2seg.logger import add_file_handler, dict2str, logger\n",
    "from tomo2seg.model import Model as Tomo2SegModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this registers a custom exception handler for the whole current notebook\n",
    "get_ipython().set_custom_exc((Exception,), slackme.custom_exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_host = hosts.hosts[socket.gethostname()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "manual-input"
    ]
   },
   "outputs": [],
   "source": [
    "# [manual-input]\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    this_nb_name: str\n",
    "    volume_name: str\n",
    "    volume_version: str\n",
    "    partition: str  # its alias...\n",
    "    \n",
    "    random_state_seed: int = 42\n",
    "    runid: int = field(default_factory=lambda: int(time.time()))\n",
    "\n",
    "args = Args(\n",
    "    this_nb_name = \"compare-models-00.ipynb\",\n",
    "    volume_name=tomo2seg_datasets.VOLUME_COMPOSITE_V1[0],\n",
    "    volume_version=tomo2seg_datasets.VOLUME_COMPOSITE_V1[1],\n",
    "    partition=\"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"args\\n{dict2str(asdict(args))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimation volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_fullname = tomo2seg_data.Volume.name_pieces2fullname(name=args.volume_name, version=args.volume_version)\n",
    "\n",
    "logger.debug(f\"{volume_fullname=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.449]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.513]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.548]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.579]\n",
      "not enough values to unpack (expected 8, got 1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 1)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.580]\n",
      "not enough values to unpack (expected 8, got 1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 1)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.582]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.583]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.584]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.585]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.597]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.623]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.648]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.671]\n",
      "not enough values to unpack (expected 8, got 1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 1)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.672]\n",
      "not enough values to unpack (expected 8, got 1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 1)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.673]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.674]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.695]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.714]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.715]\n",
      "not enough values to unpack (expected 8, got 1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 1)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.716]\n",
      "not enough values to unpack (expected 8, got 1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 1)\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.717]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.735]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.752]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.753]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.769]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.786]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.787]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.804]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.820]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.821]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "ERROR::tomo2seg::{data.py:from_fullname:465}::[2021-02-19::12:11:54.822]\n",
      "not enough values to unpack (expected 8, got 2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/data.py\", line 461, in from_fullname\n",
      "    vol_name, vol_version, partition_name, model_master_name, model_version, model_fold, model_runid, runid = full_name.split(\".\")\n",
      "ValueError: not enough values to unpack (expected 8, got 2)\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.823]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.839]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.856]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.872]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.889]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.905]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.922]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{data.py:from_fullname:502}::[2021-02-19::12:11:54.939]\n",
      "Creating volume object to get partition dimensions.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-15-b47c35092369>:<module>:023}::[2021-02-19::12:11:54.955]\n",
      "len(estimation_volumes)=22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datadir_paths = [\n",
    "    tomo2seg_data.data_dir / name\n",
    "    for name in os.listdir(tomo2seg_data.data_dir)\n",
    "]\n",
    "\n",
    "estimation_volumes = []\n",
    "\n",
    "for path in datadir_paths:\n",
    "    \n",
    "    try:\n",
    "        ev = tomo2seg_data.EstimationVolume.from_fullname(path.name)\n",
    "    \n",
    "    except ValueError as ex:\n",
    "        \n",
    "        if \"not an estimation volume\" not in ex.args[0]:\n",
    "            raise ex\n",
    "            \n",
    "        continue\n",
    "    \n",
    "    if ev.volume_fullname == volume_fullname and ev.partition.alias == args.partition:\n",
    "        estimation_volumes.append(ev)\n",
    "        \n",
    "logger.info(f\"{len(estimation_volumes)=}\")\n",
    "\n",
    "all_estimation_volumes = copy.deepcopy(estimation_volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"paper-unet-2d.f16-stripping-depth2.fold000.1611-686-349\",\n",
      "\"paper-unet-2d.f16-stripping-depth4.fold000.1611-705-025\",\n",
      "\"paper-unet-2d.f16-stripping-layernorm.fold000.1612-341-593\",\n",
      "\"paper-unet-2d.f16-stripping-no_batchnorm.fold000.1611-679-491\",\n",
      "\"paper-unet-2d.f16-stripping-no_data_augm.fold000.1611-701-054\",\n",
      "\"paper-unet-2d.f16-stripping-no_dropout.fold000.1611-692-890\",\n",
      "\"paper-unet-2d.f16-stripping-no_residual.fold000.1611-689-593\",\n",
      "\"paper-unet-2d.f16-stripping-no_sigma.fold000.1611-697-019\",\n",
      "\"paper-unet-2d.f16-stripping-rigid-updown.fold000.1611-683-325\",\n",
      "\"paper-unet-2d.f16-stripping-sepconv.fold000.1611-674-526\",\n",
      "\"paper-unet-2d.full-f08.fold000.1611-747-344\",\n",
      "\"paper-unet-2d.full-f16.fold000.1611-743-205\",\n",
      "\"paper-unet-2d.full-f24.fold000.1611-749-772\",\n",
      "\"paper-unet-2d.full-f32.fold000.1612-356-814\",\n",
      "\"paper-unet-2halfd.full-f08.fold000.1611-757-276\",\n",
      "\"paper-unet-2halfd.full-f16.fold000.1611-738-397\",\n",
      "\"paper-unet-2halfd.full-f24.fold000.1611-762-282\",\n",
      "\"paper-unet-2halfd.full-f32.fold000.1611-769-553\",\n",
      "\"paper-unet-3d.full-f08.fold000.1611-801-655\",\n",
      "\"paper-unet-3d.full-f16.fold000.1611-791-573\",\n",
      "\"paper-unet-3d.full-f24.fold000.1611-807-271\",\n",
      "\"paper-unet-3d.full-f32.fold000.1611-826-805\",\n"
     ]
    }
   ],
   "source": [
    "for ev in sorted(estimation_volumes, key=lambda x: x.model_name):\n",
    "    print(f'\"{ev.model_name}\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "manual-input"
    ]
   },
   "outputs": [],
   "source": [
    "# [manual-input]\n",
    "models_to_compare = {\n",
    "    # model vars\n",
    "#     \"2D (f0=08)\": \"paper-unet-2d.full-f08.fold000.1611-747-344\",\n",
    "#     \"2D (f0=16)\": \"paper-unet-2d.full-f16.fold000.1611-743-205\",\n",
    "#     \"2D (f0=24)\": \"paper-unet-2d.full-f24.fold000.1611-749-772\",\n",
    "    \"2D (f0=32)\": \"paper-unet-2d.full-f32.fold000.1612-356-814\",\n",
    "    \n",
    "#     \"2.5D (f0=08)\": \"paper-unet-2halfd.full-f08.fold000.1611-757-276\",\n",
    "#     \"2.5D (f0=16)\": \"paper-unet-2halfd.full-f16.fold000.1611-738-397\",\n",
    "#     \"2.5D (f0=24)\": \"paper-unet-2halfd.full-f24.fold000.1611-762-282\",\n",
    "#     \"2.5D (f0=32)\": \"paper-unet-2halfd.full-f32.fold000.1611-769-553\",\n",
    "    \n",
    "#     \"3D (f0=08)\": \"paper-unet-3d.full-f08.fold000.1611-801-655\",\n",
    "#     \"3D (f0=16)\": \"paper-unet-3d.full-f16.fold000.1611-791-573\",\n",
    "#     \"3D (f0=24)\": \"paper-unet-3d.full-f24.fold000.1611-807-271\",\n",
    "#     \"3D (f0=32)\": \"paper-unet-3d.full-f32.fold000.1611-826-805\",\n",
    "    \n",
    "    # model stripping\n",
    "#     \"depth=2\": \"paper-unet-2d.f16-stripping-depth2.fold000.1611-686-349\",\n",
    "#     \"depth=4\": \"paper-unet-2d.f16-stripping-depth4.fold000.1611-705-025\",\n",
    "#     \"no BatchNorm\": \"paper-unet-2d.f16-stripping-no_batchnorm.fold000.1611-679-491\",\n",
    "#     \"no data augm.\": \"paper-unet-2d.f16-stripping-no_data_augm.fold000.1611-701-054\",\n",
    "#     \"no Dropout\": \"paper-unet-2d.f16-stripping-no_dropout.fold000.1611-692-890\",\n",
    "#     \"no residual\": \"paper-unet-2d.f16-stripping-no_residual.fold000.1611-689-593\",\n",
    "#     \"no GaussianNoise\": \"paper-unet-2d.f16-stripping-no_sigma.fold000.1611-697-019\",\n",
    "#     \"rigid Up/DownSampling\": \"paper-unet-2d.f16-stripping-rigid-updown.fold000.1611-683-325\",\n",
    "#     \"SeparableConv\": \"paper-unet-2d.f16-stripping-sepconv.fold000.1611-674-526\",\n",
    "    \"LayerNorm\": \"paper-unet-2d.f16-stripping-layernorm.fold000.1612-341-593\",\n",
    "}\n",
    "\n",
    "models_to_compare_inv = dict(map(reversed, models_to_compare.items()))\n",
    "\n",
    "estimation_volumes_dict = {\n",
    "    models_to_compare_inv[ev.model_name]: ev\n",
    "    for ev in estimation_volumes\n",
    "    if ev.model_name in models_to_compare_inv\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(estimation_volumes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nparams(model_name):\n",
    "    t2s_model = Tomo2SegModel.build_from_model_name(model_name)\n",
    "    summary = t2s_model.summary_path.read_text()\n",
    "    trainable_params_line = summary.split(\"\\n\")[-4]\n",
    "    trainable_params_str = trainable_params_line.split(\" \")[-1]\n",
    "    return int(\"\".join(trainable_params_str.split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_history(model_name):\n",
    "    t2s_model = Tomo2SegModel.build_from_model_name(model_name)\n",
    "    df = pd.read_csv(t2s_model.history_path).set_index(\"epoch\")\n",
    "    df[\"batches\"] = df[\"train.epoch_size\"].cumsum()\n",
    "    df[\"crops\"] = (df[\"train.epoch_size\"] * df[\"train.batch_size\"]).cumsum()\n",
    "    import operator\n",
    "    crop_nvoxels = functools.reduce(operator.mul, ast.literal_eval(df[\"train.crop_shape\"][0]))\n",
    "    df[\"voxels\"] = (df[\"train.epoch_size\"] * df[\"train.batch_size\"] * crop_nvoxels).cumsum()\n",
    "    df[\"seconds\"] = df[\"seconds\"].cumsum()\n",
    "    df[\"hours\"] = df[\"seconds\"] / 60 / 60\n",
    "    df[\"val_loss_cummin\"] = np.array([\n",
    "        df[\"val_loss\"].values[:i].min()\n",
    "        for i in [1] + list(range(1, df[\"val_loss\"].shape[0])) \n",
    "    ])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = get_model_history(\"paper-unet-2d.full-f08.fold000.1611-747-344\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomo2seg.analyse_pred import AnalysePredOuputs\n",
    "is_new_dir = True\n",
    "\n",
    "def get_records(estimation_volumes_dict, metrics=(\"jaccard\", )):\n",
    "    \n",
    "    records = []\n",
    "\n",
    "    metric_cols = {}\n",
    "\n",
    "    for model_alias, ev in estimation_volumes_dict.items():\n",
    "\n",
    "        record = {}\n",
    "        \n",
    "        hist = get_model_history(ev.model_name)\n",
    "\n",
    "        record[\"model\"] = ev.model_name\n",
    "        record[\"alias\"] = model_alias\n",
    "        record[\"nparams\"] = get_nparams(ev.model_name)\n",
    "        \n",
    "        if is_new_dir:\n",
    "            outputs = AnalysePredOuputs(ev.dir / \"pred-analysis\")\n",
    "            ev_classif_report = pd.read_csv(outputs.classification_report_table_csv).set_index(\"class/average\")\n",
    "        else:\n",
    "            ev_classif_report = pd.read_csv(ev.classification_report_table_exact_csv_path).set_index(\"class/average\")\n",
    "\n",
    "        for m in metrics:\n",
    "\n",
    "            mcols = metric_cols[m] = []\n",
    "\n",
    "            for row in ev_classif_report.index:\n",
    "                col = f\"{m}.{row}\"\n",
    "                mcols.append(col)\n",
    "                record[col] = ev_classif_report.loc[row][m]\n",
    "                \n",
    "        record[\"estimation_volume\"] = ev.fullname\n",
    "        record[\"training-hours\"] = hist[\"hours\"].values[-1]\n",
    "        records.append(record)\n",
    "        \n",
    "    return records\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(get_records(estimation_volumes_dict)).set_index(\"model\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>nparams</th>\n",
       "      <th>jaccard.matrix</th>\n",
       "      <th>jaccard.fiber</th>\n",
       "      <th>jaccard.porosity</th>\n",
       "      <th>jaccard.macro</th>\n",
       "      <th>training-hours</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>paper-unet-2d.f16-stripping-layernorm.fold000.1612-341-593</th>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>3302883</td>\n",
       "      <td>0.987484</td>\n",
       "      <td>0.952605</td>\n",
       "      <td>0.645879</td>\n",
       "      <td>0.861989</td>\n",
       "      <td>3.794560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper-unet-2d.full-f32.fold000.1612-356-814</th>\n",
       "      <td>2D (f0=32)</td>\n",
       "      <td>13195203</td>\n",
       "      <td>0.988192</td>\n",
       "      <td>0.954790</td>\n",
       "      <td>0.663305</td>\n",
       "      <td>0.868763</td>\n",
       "      <td>2.830493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         alias   nparams  \\\n",
       "model                                                                      \n",
       "paper-unet-2d.f16-stripping-layernorm.fold000.1...   LayerNorm   3302883   \n",
       "paper-unet-2d.full-f32.fold000.1612-356-814         2D (f0=32)  13195203   \n",
       "\n",
       "                                                    jaccard.matrix  \\\n",
       "model                                                                \n",
       "paper-unet-2d.f16-stripping-layernorm.fold000.1...        0.987484   \n",
       "paper-unet-2d.full-f32.fold000.1612-356-814               0.988192   \n",
       "\n",
       "                                                    jaccard.fiber  \\\n",
       "model                                                               \n",
       "paper-unet-2d.f16-stripping-layernorm.fold000.1...       0.952605   \n",
       "paper-unet-2d.full-f32.fold000.1612-356-814              0.954790   \n",
       "\n",
       "                                                    jaccard.porosity  \\\n",
       "model                                                                  \n",
       "paper-unet-2d.f16-stripping-layernorm.fold000.1...          0.645879   \n",
       "paper-unet-2d.full-f32.fold000.1612-356-814                 0.663305   \n",
       "\n",
       "                                                    jaccard.macro  \\\n",
       "model                                                               \n",
       "paper-unet-2d.f16-stripping-layernorm.fold000.1...       0.861989   \n",
       "paper-unet-2d.full-f32.fold000.1612-356-814              0.868763   \n",
       "\n",
       "                                                    training-hours  \n",
       "model                                                               \n",
       "paper-unet-2d.f16-stripping-layernorm.fold000.1...        3.794560  \n",
       "paper-unet-2d.full-f32.fold000.1612-356-814               2.830493  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_index()[[\"alias\", \"nparams\", \"jaccard.matrix\", \"jaccard.fiber\", \"jaccard.porosity\", \"jaccard.macro\", \"training-hours\"]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.to_csv(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "def plot(xaxis, yaxis, models_to_compare, color_map):\n",
    "    \n",
    "    hists = {\n",
    "        mod: get_model_history(mod)\n",
    "        for mod in models_to_compare\n",
    "    }\n",
    "    \n",
    "    fig, axs = plt.subplots(\n",
    "        nrows := 1, ncols := 2, figsize=(ncols * (sz := 6) * 2, nrows * sz), dpi=120,\n",
    "    #     sharex=True,\n",
    "        gridspec_kw=dict(hspace=sz/12, wspace=sz/36)\n",
    "    )\n",
    "\n",
    "    ax, axzoom = axs\n",
    "\n",
    "    for mod, hist in hists.items():\n",
    "\n",
    "        xs = hist[xaxis] if xaxis != \"epoch\" else hist.index\n",
    "        ys = hist[yaxis]\n",
    "\n",
    "        color = next(v for k, v in color_map.items() if k in mod)\n",
    "\n",
    "        plot_kwargs = dict(\n",
    "            label=mod,\n",
    "            ls=\"--\" if \"sep\" in mod else \"-\",\n",
    "            color=color,\n",
    "            linewidth=.7,\n",
    "        )\n",
    "\n",
    "        ax.plot(xs, ys, **plot_kwargs)\n",
    "        axzoom.plot(xs, ys, **plot_kwargs)\n",
    "\n",
    "    # configs in common\n",
    "    for ax_ in axs:\n",
    "        ax_.yaxis.set_major_formatter(plt.FormatStrFormatter(\"%.2f\"))\n",
    "        ax_.set_ybound(lower=0)\n",
    "        ax_.set_xlabel(xaxis)\n",
    "        ax_.legend()\n",
    "        ax_.set_ylabel(\"jaccard2 (lower is better)\")\n",
    "\n",
    "    ax.set_ybound(upper=.7)\n",
    "    ax.set_title(f\"{yaxis} history\")\n",
    "\n",
    "    axzoom.set_yscale(\"log\")\n",
    "    axzoom.set_ybound(upper=.03)\n",
    "    axzoom.set_title(\"zoom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conv types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d-sep/unet2d-sep.vanilla03-f16.fold000.1606-575-226/history.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-dafeeeded342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_conv_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# plot(\"hours\", \"val_loss\", compare_conv_type, color_map)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_loss_cummin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_conv_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-281b35df3b23>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(xaxis, yaxis, models_to_compare, color_map)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_to_compare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     hists = {\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_to_compare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-281b35df3b23>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     hists = {\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_to_compare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     }\n",
      "\u001b[0;32m<ipython-input-20-3bd293102a5b>\u001b[0m in \u001b[0;36mget_model_history\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mt2s_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTomo2SegModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_from_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2s_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batches\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train.epoch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"crops\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train.epoch_size\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train.batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d-sep/unet2d-sep.vanilla03-f16.fold000.1606-575-226/history.csv'"
     ]
    }
   ],
   "source": [
    "compare_conv_type = [\n",
    "    \"unet2d-sep.vanilla03-f16.fold000.1606-575-226\",\n",
    "    \"unet2d.vanilla03-f16.fold000.1606-505-109\",\n",
    "    \"unet2halfd-sep.vanilla03-f16.fold000.1606-729-672\",\n",
    "    \"unet2halfd.vanilla03-f16.fold000.1606-683-705\",\n",
    "    \"unet3d.vanilla03-f08.fold000.1606-842-005\",\n",
    "    \"unet3d.vanilla03-f16.fold000.1606-750-939\",\n",
    "]\n",
    "\n",
    "color_map = {\n",
    "    \"2d\": dft_colors[0],\n",
    "    \"2halfd\": dft_colors[1],\n",
    "    \"3d.vanilla03-f08\": dft_colors[2],\n",
    "    \"3d.vanilla03-f16\": dft_colors[3],\n",
    "}\n",
    "\n",
    "plot(\"epoch\", \"val_loss\", compare_conv_type, color_map)\n",
    "# plot(\"hours\", \"val_loss\", compare_conv_type, color_map)\n",
    "plot(\"epoch\", \"val_loss_cummin\", compare_conv_type, color_map)\n",
    "plot(\"voxels\", \"val_loss_cummin\", compare_conv_type, color_map)\n",
    "plot(\"hours\", \"val_loss_cummin\", compare_conv_type, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conv types (no separable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_conv_type = [\n",
    "    \"unet2d.vanilla03-f16.fold000.1606-505-109\",\n",
    "    \"unet2halfd.vanilla03-f16.fold000.1606-683-705\",\n",
    "#     \"unet3d.vanilla03-f08.fold000.1606-842-005\",\n",
    "    \"unet3d.vanilla03-f16.fold000.1606-750-939\",\n",
    "]\n",
    "\n",
    "color_map = {\n",
    "    \"2d\": dft_colors[0],\n",
    "    \"2halfd\": dft_colors[1],\n",
    "    \"3d.vanilla03-f08\": dft_colors[2],\n",
    "    \"3d.vanilla03-f16\": dft_colors[3],\n",
    "}\n",
    "\n",
    "# plot(\"epoch\", \"val_loss\", compare_conv_type, color_map)\n",
    "# plot(\"hours\", \"val_loss\", compare_conv_type, color_map)\n",
    "plot(\"epoch\", \"val_loss_cummin\", compare_conv_type, color_map)\n",
    "plot(\"voxels\", \"val_loss_cummin\", compare_conv_type, color_map)\n",
    "plot(\"hours\", \"val_loss_cummin\", compare_conv_type, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crop sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_crop_sizes = [\n",
    "    \"unet2d.crop48-f16.fold000.1607-530-580\",\n",
    "    \"unet2d.crop112-f16.fold000.1607-533-765\",\n",
    "    \"unet2d.vanilla03-f16.fold000.1606-505-109\",\n",
    "]\n",
    "\n",
    "color_map = {\n",
    "    \"crop48\": dft_colors[0],\n",
    "    \"crop112\": dft_colors[1],\n",
    "    \"vanilla03\": dft_colors[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(\"epoch\", \"val_loss\", compare_crop_sizes, color_map)\n",
    "# plot(\"hours\", \"val_loss\", compare_crop_sizes, color_map)\n",
    "plot(\"epoch\", \"val_loss_cummin\", compare_crop_sizes, color_map)\n",
    "plot(\"hours\", \"val_loss_cummin\", compare_crop_sizes, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_crop_sizes = [\n",
    "    \"unet2halfd.crop112-f16.fold000.1607-788-628\",\n",
    "    \"unet2halfd.vanilla03-f16.fold000.1606-683-705\",\n",
    "\n",
    "    \"unet2halfd-sep.crop112-f16.fold000.1607-789-290\",\n",
    "    \"unet2halfd-sep.vanilla03-f16.fold000.1606-729-672\",\n",
    "]\n",
    "\n",
    "color_map = {\n",
    "    \"crop112\": dft_colors[1],\n",
    "    \"vanilla03\": dft_colors[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(\"epoch\", \"val_loss\", compare_crop_sizes, color_map)\n",
    "# plot(\"hours\", \"val_loss\", compare_crop_sizes, color_map)\n",
    "plot(\"epoch\", \"val_loss_cummin\", compare_crop_sizes, color_map)\n",
    "plot(\"hours\", \"val_loss_cummin\", compare_crop_sizes, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_crop_sizes = [\n",
    "    \"unet3d.vanilla03-f08.fold000.1606-842-005\",\n",
    "    \"unet3d.crop96-f08.fold000.1607-109-265\",\n",
    "    \"unet3d.crop112-f12.fold000.1607-466-349\",\n",
    "    \"unet3d.crop304-f16.fold000.1607-790-699\",\n",
    "]\n",
    "\n",
    "color_map = {\n",
    "    \"vanilla03\": dft_colors[0],\n",
    "    \"crop96\": dft_colors[1],\n",
    "    \"crop112\": dft_colors[2],\n",
    "    \"crop304\": dft_colors[3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(\"epoch\", \"val_loss\", compare_crop_sizes, color_map)\n",
    "# plot(\"hours\", \"val_loss\", compare_crop_sizes, color_map)\n",
    "plot(\"epoch\", \"val_loss_cummin\", compare_crop_sizes, color_map)\n",
    "plot(\"hours\", \"val_loss_cummin\", compare_crop_sizes, color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
